{
  "error": "json_parse_failed",
  "raw_response": "```json\n{\n  \"extraction_metadata\": {\n    \"version\": \"v14_3_3\",\n    \"total_relationships\": 101,\n    \"analysis_timestamp\": \"2025-10-15T08:44:47.743740\"\n  },\n  \"quality_summary\": {\n    \"critical_issues\": 1,\n    \"high_priority_issues\": 0,\n    \"medium_priority_issues\": 3,\n    \"mild_issues\": 8,\n    \"total_issues\": 12,\n    \"issue_rate_percent\": 11.9,\n    \"estimated_false_negative_rate\": 0.08,\n    \"estimated_total_issues_with_fn\": 13,\n    \"adjusted_issue_rate_percent\": 12.9,\n    \"grade_confirmed\": \"B\",\n    \"grade_adjusted\": \"B\",\n    \"note\": \"Significant improvement from V4 (30.8% \u2192 11.9%). The dedication normalization module successfully fixed the 'Our Biggest Deal to X' pattern. Remaining issues: 1 reversed authorship (CRITICAL), 3 incomplete titles (MEDIUM), 8 praise quotes as endorsements (MILD). System is approaching production quality threshold of 5%.\"\n  },\n  \"issue_categories\": [\n    {\n      \"category_name\": \"Reversed Authorship\",\n      \"severity\": \"CRITICAL\",\n      \"count\": 1,\n      \"percentage\": 1.0,\n      \"description\": \"Book title appears as source instead of author in authorship relationship\",\n      \"root_cause_hypothesis\": \"Pass 1 extraction prompt may not clearly distinguish between 'X authored Y' vs 'Y authored by X' patterns in bibliographic citations. The bibliographic_parser module detected this but flagged it rather than auto-correcting.\",\n      \"affected_module\": \"modules/pass2_5_postprocessing/bibliographic_parser.py\",\n      \"affected_prompt\": \"prompts/pass1_extraction_v7.txt\",\n      \"affected_config\": null,\n      \"examples\": [\n        {\n          \"source\": \"Our Biggest Deal\",\n          \"relationship\": \"authored\",\n          \"target\": \"Aaron William Perry\",\n          \"evidence_text\": \"Perry, Aaron William. Our Biggest Deal : pathways to planetary prosperity / by Aaron William Perry ; foreword by John Fullerton.\",\n          \"page\": 4,\n          \"what_is_wrong\": \"Book title is source, author is target - relationship is reversed\",\n          \"should_be\": {\n            \"source\": \"Aaron William Perry\",\n            \"relationship\": \"authored\",\n            \"target\": \"Our Biggest Deal\"\n          }\n        }\n      ]\n    },\n    {\n      \"category_name\": \"Incomplete Titles\",\n      \"severity\": \"MEDIUM\",\n      \"count\": 3,\n      \"percentage\": 3.0,\n      \"description\": \"Book/essay titles that are too short (1-2 words) and likely incomplete\",\n      \"root_cause_hypothesis\": \"Pass 1 extraction may be truncating titles when they appear in certain contexts. The incomplete_title_detector flags these but doesn't have enough context to reconstruct the full title.\",\n      \"affected_module\": \"modules/pass2_5_postprocessing/incomplete_title_detector.py\",\n      \"affected_prompt\": \"prompts/pass1_extraction_v7.txt\",\n      \"affected_config\": null,\n      \"examples\": [\n        {\n          \"source\": \"John Fullerton\",\n          \"relationship\": \"authored\",\n          \"target\": \"Regenerative Capitalism\",\n          \"evidence_text\": \"John Fullerton is the author of Regenerative Capitalism\",\n          \"page\": 18,\n          \"what_is_wrong\": \"Title is likely incomplete - should include subtitle or full title\",\n          \"should_be\": {\n            \"source\": \"John Fullerton\",\n            \"relationship\": \"authored\",\n            \"target\": \"Regenerative Capitalism: How Universal Principles and Patterns Will Shape Our New Economy (or similar full title)\"\n          }\n        },\n        {\n          \"source\": \"John Fullerton\",\n          \"relationship\": \"authored\",\n          \"target\": \"Regenerative Economics\",\n          \"evidence_text\": \"John Fullerton is the author of Regenerative Economics (forthcoming)\",\n          \"page\": 18,\n          \"what_is_wrong\": \"Title is likely incomplete - 2 words is suspiciously short for a book title\",\n          \"should_be\": {\n            \"source\": \"John Fullerton\",\n            \"relationship\": \"authored\",\n            \"target\": \"Regenerative Economics (full title unknown - marked as forthcoming)\"\n          }\n        },\n        {\n          \"source\": \"Aaron William Perry\",\n          \"relationship\": \"authored\",\n          \"target\": \"Viriditas\",\n          \"evidence_text\": \"This collection builds on Perry's previous books Y on Earth and Viriditas\",\n          \"page\": 23,\n          \"what_is_wrong\": \"Single-word title may be incomplete or lack subtitle\",\n          \"should_be\": {\n            \"source\": \"Aaron William Perry\",\n            \"relationship\": \"authored\",\n            \"target\": \"Viriditas: The Life Force in Psyche and Cosmos (or similar full title)\"\n          }\n        }\n      ]\n    },\n    {\n      \"category_name\": \"Praise Quotes Misclassified as Endorsements\",\n      \"severity\": \"MILD\",\n      \"count\": 8,\n      \"percentage\": 7.9,\n      \"description\": \"Endorsement quotes from book cover/front matter treated as factual endorsement relationships rather than promotional content\",\n      \"root_cause_hypothesis\": \"Pass 1 extraction treats all 'Person says positive thing about Book' as endorsement relationships. The praise_quote_corrector module detects some of these (1 case) but misses others. This is borderline acceptable since endorsements ARE factual, just not substantive knowledge.\",\n      \"affected_module\": \"modules/pass2_5_postprocessing/praise_quote_corrector.py\",\n      \"affected_prompt\": \"prompts/pass1_extraction_v7.txt\",\n      \"affected_config\": null,\n      \"examples\": [\n        {\n          \"source\": \"Ken LaRoe\",\n          \"relationship\": \"endorsed\",\n          \"target\": \"Our Biggest Deal\",\n          \"evidence_text\": \"I pick up his book, Our Biggest Deal, and read the amazing authors and study the amazing companies featured and I become completely energized to pick up the sword again! \u2014Ken LaRoe, Founder & Chairman, Climate First Bank\",\n          \"page\": 3,\n          \"what_is_wrong\": \"This is a promotional quote from the book's front matter, not a substantive knowledge relationship. While factually true, it doesn't convey useful information for a knowledge graph.\",\n          \"should_be\": {\n            \"source\": \"Ken LaRoe\",\n            \"relationship\": \"provided promotional quote for\",\n            \"target\": \"Our Biggest Deal\"\n          }\n        },\n        {\n          \"source\": \"Samantha Power\",\n          \"relationship\": \"endorsed\",\n          \"target\": \"Our Biggest Deal\",\n          \"evidence_text\": \"Now more than ever, we need imagination as a force for systems change and planetary healing. The stories and frameworks in Our Biggest Deal bring that force vividly to life.\" \u2014Samantha Power, Founder, BioFi Bio-Regional Finance\",\n          \"page\": 3,\n          \"what_is_wrong\": \"Promotional quote from front matter\",\n          \"should_be\": {\n            \"source\": \"Samantha Power\",\n            \"relationship\": \"provided promotional quote for\",\n            \"target\": \"Our Biggest Deal\"\n          }\n        },\n        {\n          \"source\": \"Paul Kevin Kennon\",\n          \"relationship\": \"endorsed\",\n          \"target\": \"Our Biggest Deal\",\n          \"evidence_text\": \"Our Biggest Deal reads like an operator's manual for prosperity that lasts. Perry replaces vague intent with measurable pathways\u2014financeable, buildable, repeatable. For investors, policymakers, and builders who want returns and regeneration to be the same plan, not competing goals.\" \u2014Paul Kevin Kennon, AIA, Founder & CEO, Beyond Zero Luxury Wilderness Resorts\",\n          \"page\": 3,\n          \"what_is_wrong\": \"Promotional quote from front matter\",\n          \"should_be\": {\n            \"source\": \"Paul Kevin Kennon\",\n            \"relationship\": \"provided promotional quote for\",\n            \"target\": \"Our Biggest Deal\"\n          }\n        }\n      ]\n    },\n    {\n      \"category_name\": \"Metaphorical Relationships Treated as Factual\",\n      \"severity\": \"MILD\",\n      \"count\": 3,\n      \"percentage\": 3.0,\n      \"description\": \"Metaphorical or figurative language extracted as literal factual relationships\",\n      \"root_cause_hypothesis\": \"Pass 2 evaluation correctly flags these with METAPHOR or FIGURATIVE_LANGUAGE classification, but they still pass through with FACTUAL flag. The system is detecting the issue but not filtering these out.\",\n      \"affected_module\": \"modules/pass2_evaluation/dual_signal_evaluator.py\",\n      \"affected_prompt\": \"prompts/pass2_evaluation_v7.txt\",\n      \"affected_config\": null,\n      \"examples\": [\n        {\n          \"source\": \"2008 financial crash\",\n          \"relationship\": \"described as\",\n          \"target\": \"act of violence\",\n          \"evidence_text\": \"The 2008 financial crash was an act of violence.\",\n          \"page\": 28,\n          \"what_is_wrong\": \"This is metaphorical language, not a factual claim. The crash was not literally an act of violence.\",\n          \"should_be\": {\n            \"source\": \"2008 financial crash\",\n            \"relationship\": \"caused\",\n            \"target\": \"economic harm\"\n          }\n        },\n        {\n          \"source\": \"Facebook's algorithms\",\n          \"relationship\": \"described as\",\n          \"target\": \"act of violence\",\n          \"evidence_text\": \"Facebook's algorithms are an act of violence.\",\n          \"page\": 28,\n          \"what_is_wrong\": \"Metaphorical statement, not factual\",\n          \"should_be\": {\n            \"source\": \"Facebook's algorithms\",\n            \"relationship\": \"impact\",\n            \"target\": \"user behavior\"\n          }\n        },\n        {\n          \"source\": \"Buckminster Fuller\",\n          \"relationship\": \"foresaw\",\n          \"target\": \"knife's edge\",\n          \"evidence_text\": \"Make no mistake, we are on a knife's edge as Bucky Fuller foresaw a half century ago.\",\n          \"page\": 28,\n          \"what_is_wrong\": \"'Knife's edge' is a metaphor for precarious situation, not a literal object\",\n          \"should_be\": {\n            \"source\": \"Buckminster Fuller\",\n            \"relationship\": \"predicted\",\n            \"target\": \"critical juncture for humanity\"\n          }\n        }\n      ]\n    }\n  ],\n  \"novel_error_patterns\": [\n    {\n      \"pattern_name\": \"Philosophical Claims as Factual Relationships\",\n      \"severity\": \"MILD\",\n      \"count\": 2,\n      \"description\": \"Abstract philosophical statements extracted as concrete factual relationships\",\n      \"root_cause_hypothesis\": \"Pass 1 extraction doesn't distinguish between empirical facts and philosophical/normative claims. These are flagged as PHILOSOPHICAL_CLAIM but still marked FACTUAL.\",\n      \"affected_module\": \"modules/pass2_evaluation/dual_signal_evaluator.py\",\n      \"examples\": [\n        {\n          \"source\": \"Rene Descartes\",\n          \"relationship\": \"quoted\",\n          \"target\": \"The conquest of nature is to be achieved through number and measure\",\n          \"evidence_text\": \"Descartes's views on nature are reflected in this quote attributed to him\",\n          \"page\": 26,\n          \"what_is_wrong\": \"This is a philosophical/normative statement, not an empirical fact. It expresses a worldview, not a testable claim.\",\n          \"should_be\": {\n            \"source\": \"Rene Descartes\",\n            \"relationship\": \"expressed philosophy\",\n            \"target\": \"mechanistic view of nature\"\n          }\n        }\n      ]\n    }\n  ],\n  \"improvement_recommendations\": [\n    {\n      \"priority\": \"CRITICAL\",\n      \"type\": \"CODE_FIX\",\n      \"target_file\": \"modules/pass2_5_postprocessing/bibliographic_parser.py\",\n      \"recommendation\": \"Auto-correct reversed authorship instead of just flagging. When AUTHORSHIP_REVERSED flag is set, swap source and target automatically. Add confidence threshold: only auto-correct if p_true > 0.9 and text_confidence > 0.95.\",\n      \"expected_impact\": \"Eliminates the 1 remaining reversed authorship error (1% of relationships)\",\n      \"rationale\": \"The module already detects this pattern correctly. Auto-correction is safe given the high confidence scores and clear bibliographic citation pattern.\"\n    },\n    {\n      \"priority\": \"HIGH\",\n      \"type\": \"PROMPT_ENHANCEMENT\",\n      \"target_file\": \"prompts/pass1_extraction_v7.txt\",\n      \"recommendation\": \"Add explicit instruction about authorship direction: 'For authorship relationships, ALWAYS extract as (Author) \u2192 authored \u2192 (Work), never (Work) \u2192 authored \u2192 (Author). Example: (Jane Smith) \u2192 authored \u2192 (The Great Book), NOT (The Great Book) \u2192 authored \u2192 (Jane Smith).' Add 2-3 few-shot examples showing correct authorship direction.\",\n      \"expected_impact\": \"Prevents reversed authorship errors at source, reducing reliance on post-processing fixes\",\n      \"rationale\": \"Fixing at extraction time is more robust than post-processing. Clear examples will help LLM learn the correct pattern.\"\n    },\n    {\n      \"priority\": \"HIGH\",\n      \"type\": \"CODE_FIX\",\n      \"target_file\": \"modules/pass2_5_postprocessing/incomplete_title_detector.py\",\n      \"recommendation\": \"Enhance title completion logic: (1) Check if title appears elsewhere in document with more context, (2) For 1-2 word titles, search for subtitle patterns (': ', ' - ', ' | '), (3) If title is marked 'forthcoming', append '(forthcoming)' to indicate incompleteness rather than flagging as error.\",\n      \"expected_impact\": \"Reduces incomplete title errors from 3% to <1%\",\n      \"rationale\": \"Many incomplete titles can be completed by looking at other mentions in the document. This is a code-solvable problem.\"\n    },\n    {\n      \"priority\": \"MEDIUM\",\n      \"type\": \"PROMPT_ENHANCEMENT\",\n      \"target_file\": \"prompts/pass1_extraction_v7.txt\",\n      \"recommendation\": \"Add instruction: 'When extracting book/article titles, include the FULL title with subtitle if present. Examples: \\\"Regenerative Capitalism: How Universal Principles Will Shape Our New Economy\\\" (full), NOT \\\"Regenerative Capitalism\\\" (incomplete). If only a short title is visible, mark with [partial title] flag.'\",\n      \"expected_impact\": \"Reduces incomplete title extraction at source\",\n      \"rationale\": \"Prevention at extraction is better than detection in post-processing. Clear examples will help LLM extract complete titles.\"\n    },\n    {\n      \"priority\": \"MEDIUM\",\n      \"type\": \"CODE_FIX\",\n      \"target_file\": \"modules/pass2_5_postprocessing/praise_quote_corrector.py\",\n      \"recommendation\": \"Expand praise quote detection: (1) Check if relationship appears in first 5 pages (front matter zone), (2) Check if evidence_text contains promotional language ('amazing', 'inspiring', 'essential reading', 'highly recommend'), (3) If both conditions met, change relationship to 'provided promotional quote for' and add PROMOTIONAL_CONTENT flag.\",\n      \"expected_impact\": \"Reduces praise quote misclassification from 8% to <2%\",\n      \"rationale\": \"The module already handles some cases. Expanding detection criteria will catch more promotional content systematically.\"\n    },\n    {\n      \"priority\": \"MEDIUM\",\n      \"type\": \"CONFIG_UPDATE\",\n      \"target_file\": \"config/filtering_thresholds.yaml\",\n      \"recommendation\": \"Add filter rule: If classification_flags contains 'METAPHOR' AND p_true < 0.6, exclude relationship from final output. Rationale: Low-confidence metaphorical relationships are not useful for knowledge graphs.\",\n      \"expected_impact\": \"Filters out 3 metaphorical relationships (3% of total)\",\n      \"rationale\": \"The system already detects metaphors. Adding a filter rule leverages existing detection to improve output quality.\"\n    },\n    {\n      \"priority\": \"LOW\",\n      \"type\": \"PROMPT_ENHANCEMENT\",\n      \"target_file\": \"prompts/pass1_extraction_v7.txt\",\n      \"recommendation\": \"Add instruction: 'Avoid extracting metaphorical or figurative language as factual relationships. Examples to SKIP: \\\"X is a knife\\\\'s edge\\\", \\\"Y is an act of violence\\\" (when not literal), \\\"Z is a journey\\\". Focus on concrete, verifiable facts.'\",\n      \"expected_impact\": \"Reduces metaphorical extractions at source\",\n      \"rationale\": \"While the current 3% rate is acceptable, preventing these at extraction time reduces downstream processing burden.\"\n    },\n    {\n      \"priority\": \"LOW\",\n      \"type\": \"NEW_MODULE\",\n      \"target_file\": \"modules/pass2_5_postprocessing/philosophical_claim_filter.py\",\n      \"recommendation\": \"Create new module to detect and filter philosophical/normative claims: (1) Check for normative language ('should', 'ought', 'must'), (2) Check for abstract concepts without empirical grounding, (3) If PHILOSOPHICAL_CLAIM flag is set AND relationship doesn't convey concrete information, mark for exclusion.\",\n      \"expected_impact\": \"Filters 2 philosophical claims (2% of relationships)\",\n      \"rationale\": \"Philosophical claims are currently flagged but not filtered. A dedicated module would handle this systematically.\"\n    }\n  ],\n  \"prompt_analysis\": {\n    \"pass1_extraction_issues\": [\n      {\n        \"issue\": \"Authorship direction ambiguity - LLM extracts both (Author \u2192 Work) and (Work \u2192 Author) patterns\",\n        \"current_wording\": \"Likely: 'Extract authorship relationships between people and their works'\",\n        \"suggested_fix\": \"Add explicit directional constraint: 'For authorship, ALWAYS use pattern (Author) \u2192 authored \u2192 (Work). NEVER reverse this. Examples: (Charles Darwin) \u2192 authored \u2192 (On the Origin of Species) \u2713, (On the Origin of Species) \u2192 authored \u2192 (Charles Darwin) \u2717'\",\n        \"examples_needed\": \"Yes - add 3-5 few-shot examples showing correct authorship direction, including bibliographic citation formats\"\n      },\n      {\n        \"issue\": \"Incomplete title extraction - LLM truncates titles or extracts only main title without subtitle\",\n        \"current_wording\": \"Likely: 'Extract book and article titles mentioned in the text'\",\n        \"suggested_fix\": \"Add completeness instruction: 'Extract FULL titles including subtitles. Format: \\\"Main Title: Subtitle\\\" or \\\"Main Title - Subtitle\\\". If only partial title is visible, add [partial] flag. Examples: \\\"Regenerative Capitalism: How Universal Principles Will Shape Our New Economy\\\" \u2713, \\\"Regenerative Capitalism\\\" \u2717 (incomplete)'\",\n        \"examples_needed\": \"Yes - show examples of complete vs incomplete titles\"\n      },\n      {\n        \"issue\": \"Promotional quotes treated as substantive endorsements - LLM doesn't distinguish between promotional content and factual claims\",\n        \"current_wording\": \"Likely: 'Extract endorsement relationships when people praise or recommend works'\",\n        \"suggested_fix\": \"Add context-awareness: 'Distinguish between: (1) Promotional quotes in front matter/cover (use \\\"provided promotional quote for\\\"), (2) Substantive endorsements in body text (use \\\"endorsed\\\"). Promotional language includes: \\\"amazing\\\", \\\"inspiring\\\", \\\"must-read\\\", \\\"highly recommend\\\".'\",\n        \"examples_needed\": \"Yes - show examples of promotional vs substantive endorsements\"\n      },\n      {\n        \"issue\": \"Metaphorical language extracted as literal facts - LLM doesn't recognize figurative speech\",\n        \"current_wording\": \"Likely: 'Extract factual relationships from the text'\",\n        \"suggested_fix\": \"Add metaphor avoidance: 'Skip metaphorical/figurative language. Examples to AVOID: \\\"X is a knife\\\\'s edge\\\" (metaphor for precarious), \\\"Y is an act of violence\\\" (metaphor for harm), \\\"Z is a journey\\\" (metaphor for process). Focus on literal, verifiable facts only.'\",\n        \"examples_needed\": \"Yes - show examples of metaphors to skip vs literal facts to extract\"\n      }\n    ],\n    \"pass2_evaluation_issues\": [\n      {\n        \"issue\": \"Metaphor detection doesn't prevent extraction - relationships flagged as METAPHOR still pass through with FACTUAL flag\",\n        \"current_wording\": \"Likely: 'Evaluate whether the relationship is factually accurate'\",\n        \"suggested_fix\": \"Add exclusion logic: 'If a relationship is metaphorical or figurative (not literally true), mark it as NON_FACTUAL and recommend exclusion. Metaphorical relationships should not appear in a factual knowledge graph unless they convey concrete information.'\",\n        \"examples_needed\": \"No - this is more about evaluation logic than prompt clarity\"\n      },\n      {\n        \"issue\": \"Philosophical claims marked as FACTUAL - normative/philosophical statements not distinguished from empirical facts\",\n        \"current_wording\": \"Likely: 'Determine if the relationship represents a factual claim'\",\n        \"suggested_fix\": \"Add claim type distinction: 'Distinguish between: (1) Empirical facts (testable, observable), (2) Philosophical/normative claims (values, beliefs, prescriptions). Mark philosophical claims as PHILOSOPHICAL_CLAIM and reduce p_true score. Example: \\\"Democracy is good\\\" = philosophical, \\\"Democracy was established in 1776\\\" = empirical.'\",\n        \"examples_needed\": \"Yes - show examples of empirical vs philosophical claims\"\n      }\n    ]\n  },\n  \"system_health\": {\n    \"meets_production_criteria\": false,\n    \"target_quality_threshold\": 0.05,\n    \"current_quality_issue_rate\": 0.119,\n    \"gap_to_target\": 0.069,\n    \"estimated_relationships_to_fix\": 7,\n    \"notes\": \"System has improved dramatically from V4 (30.8% \u2192 11.9%). The dedication normalization fix was highly effective. To reach production quality (<5% issues), need to: (1) Fix reversed authorship (1%), (2) Improve title completion (3%), (3) Better filter promotional quotes (8%). The 1 CRITICAL issue is easily fixable with auto-correction. System is 69% of the way to production quality.\"\n  }\n}\n```",
  "metadata": {
    "analysis_date": "2025-10-15T08:47:23.584462",
    "relationships_analyzed": 101,
    "reflector_version": "1.0_claude",
    "model_used": "claude-sonnet-4-5-20250929",
    "extraction_version": "v14_3_3"
  }
}