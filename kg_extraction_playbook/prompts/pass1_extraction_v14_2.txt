# Extract ALL meaningful relationships from this text - including factual, bibliographic, categorical, compositional, functional, organizational, and testable claims.

## üéØ V11 GOAL: COMPREHENSIVE KNOWLEDGE EXTRACTION WITH PROPER LABELING

Extract ALL valuable data, information, knowledge, and wisdom that can be represented in graph/RDF format. This includes:
- ‚úÖ Factual relationships (authorship, publication, organizational)
- ‚úÖ Bibliographic citations (author-book, book-publisher, book-year)
- ‚úÖ Categorical relationships (is-a, is, definitions)
- ‚úÖ Compositional relationships (contains, includes, provides)
- ‚úÖ Functional relationships (produces, enhances, stimulates)
- ‚úÖ Testable claims (scientific assertions)
- ‚úÖ **NEW V11**: Philosophical statements (will be labeled as PHILOSOPHICAL_CLAIM in Pass 2)
- ‚úÖ **NEW V11**: Metaphorical language (will be labeled as METAPHOR in Pass 2 and normalized by postprocessing)
- ‚úÖ **NEW V11**: Normative prescriptions (will be labeled appropriately)

**V11 LABELING APPROACH**: Extract ALL relationships. Pass 2 evaluation will add classification_flags (FACTUAL, METAPHOR, PHILOSOPHICAL_CLAIM, etc.), and Pass 2.5 postprocessing modules will normalize/label as appropriate.

## üìö RELATIONSHIP TYPES TO EXTRACT (PRIORITY ORDER)

### 1. BIBLIOGRAPHIC (Authorship & Publication) ‚≠ê HIGH PRIORITY
Bibliographic citations are ESSENTIAL knowledge graph elements. Extract ALL of them.

‚úÖ **Extract**: (Person)-[authored]->(Book/Paper/Article)
‚úÖ **Extract**: (Book)-[published by]->(Publisher)
‚úÖ **Extract**: (Book)-[published in]->(Year/Location)
‚úÖ **Extract**: (Person)-[dedicated]->(Book to Person)
‚úÖ **Extract**: (Person)-[endorsed]->(Book)

**Example Text**: "Suzuki, David. Sacred Balance. Vancouver: Greystone, 1997."
**Extract**:
- (David Suzuki, authored, Sacred Balance)
- (Sacred Balance, published by, Greystone)
- (Sacred Balance, published in, Vancouver)
- (Sacred Balance, published in, 1997)

**Example Text**: "This handbook is dedicated to my two children, Osha and Hunter."
**Extract**:
- (Aaron Perry, dedicated, Soil Stewardship Handbook to Osha)
- (Aaron Perry, dedicated, Soil Stewardship Handbook to Hunter)

**Example Text**: "Foreword by Joel Salatin"
**Extract**:
- (Joel Salatin, wrote foreword for, Soil Stewardship Handbook)

### 2. CATEGORICAL (Definitions & Classifications) ‚≠ê HIGH PRIORITY
Categorical relationships define what things ARE. Extract ALL definitions.

‚úÖ **Extract**: (Entity)-[is-a]->(Category/Type)
‚úÖ **Extract**: (Entity)-[is]->(Definition)
‚úÖ **Extract**: (Entity)-[defined as]->(Definition)

**Example Text**: "Soil is a complex ecosystem containing bacteria, fungi, and minerals."
**Extract**:
- (soil, is-a, complex ecosystem)
- (soil, contains, bacteria)
- (soil, contains, fungi)
- (soil, contains, minerals)

**Example Text**: "Regenerative agriculture is a conservation and rehabilitation approach to food and farming systems."
**Extract**:
- (regenerative agriculture, is-a, conservation approach)
- (regenerative agriculture, is-a, rehabilitation approach)

### 3. COMPOSITIONAL (Parts & Contents) ‚≠ê HIGH PRIORITY
Compositional relationships describe what things CONTAIN or PROVIDE.

‚úÖ **Extract**: (Whole)-[contains]->(Part)
‚úÖ **Extract**: (Whole)-[includes]->(Component)
‚úÖ **Extract**: (Resource)-[provides]->(Service/Benefit)
‚úÖ **Extract**: (System)-[consists of]->(Elements)

**Example Text**: "Compost contains nitrogen, phosphorus, and beneficial microorganisms."
**Extract**:
- (compost, contains, nitrogen)
- (compost, contains, phosphorus)
- (compost, contains, beneficial microorganisms)

**Example Text**: "This handbook includes sections on cover cropping, composting, and no-till farming."
**Extract**:
- (handbook, includes, section on cover cropping)
- (handbook, includes, section on composting)
- (handbook, includes, section on no-till farming)

### 4. FUNCTIONAL (Processes & Effects) ‚≠ê HIGH PRIORITY
Functional relationships describe what things DO or how they WORK.

‚úÖ **Extract**: (Agent)-[produces]->(Product)
‚úÖ **Extract**: (Action)-[enhances]->(Outcome)
‚úÖ **Extract**: (Practice)-[stimulates]->(Effect)
‚úÖ **Extract**: (Process)-[increases]->(Result)
‚úÖ **Extract**: (Method)-[improves]->(Condition)

**Example Text**: "Cover cropping enhances soil structure and prevents erosion."
**Extract**:
- (cover cropping, enhances, soil structure)
- (cover cropping, prevents, erosion)

**Example Text**: "Mycorrhizal fungi produce enzymes that break down organic matter."
**Extract**:
- (mycorrhizal fungi, produce, enzymes)
- (enzymes, break down, organic matter)

### 5. ORGANIZATIONAL (Affiliations & Roles) ‚≠ê HIGH PRIORITY
Organizational relationships describe who WORKS WHERE and in what ROLE.

‚úÖ **Extract**: (Person)-[affiliated with]->(Organization)
‚úÖ **Extract**: (Person)-[directs]->(Organization)
‚úÖ **Extract**: (Person)-[founded]->(Organization)
‚úÖ **Extract**: (Organization)-[collaborates with]->(Organization)
‚úÖ **Extract**: (Person)-[works for]->(Organization)

**Example Text**: "Dr. Jane Smith directs the Soil Health Institute."
**Extract**:
- (Dr. Jane Smith, directs, Soil Health Institute)

**Example Text**: "Aaron Perry founded the Y on Earth Community in 2014."
**Extract**:
- (Aaron Perry, founded, Y on Earth Community)
- (Y on Earth Community, founded in, 2014)

### 6. DISCOURSE GRAPH (Claims, Evidence, Questions)
Extract ALL discourse elements for complete conversation tracking.

‚úÖ **Extract**: (Speaker)-[claims]->(Statement)
‚úÖ **Extract**: (Evidence)-[supports]->(Claim)
‚úÖ **Extract**: (Evidence)-[opposes]->(Claim)
‚úÖ **Extract**: (Question)-[addresses]->(Topic)

**Example Text**: "The speaker claims that soil is the answer to climate change."
**Extract**:
- (speaker, claims, soil is the answer to climate change)

### 7. CAUSATION & EFFECTS
Extract ALL causal relationships (factual, testable, verifiable).

‚úÖ **Extract**: (Cause)-[causes]->(Effect)
‚úÖ **Extract**: (Practice)-[leads to]->(Outcome)
‚úÖ **Extract**: (Action)-[results in]->(Consequence)

**Example Text**: "Tilling destroys soil structure and releases carbon into the atmosphere."
**Extract**:
- (tilling, destroys, soil structure)
- (tilling, releases, carbon into atmosphere)

### 8. PROCESSES & PRACTICES
Extract concrete, actionable methods and procedures.

‚úÖ **Extract**: (Method)-[involves]->(Steps)
‚úÖ **Extract**: (Practice)-[requires]->(Resources)
‚úÖ **Extract**: (Technique)-[transforms]->(Materials)

**Example Text**: "Sheet mulching involves layering cardboard, compost, and wood chips."
**Extract**:
- (sheet mulching, involves, layering cardboard)
- (sheet mulching, involves, layering compost)
- (sheet mulching, involves, layering wood chips)

### 9. QUANTITATIVE RELATIONSHIPS
Extract specific measurements and numerical data.

‚úÖ **Extract**: (Entity)-[measures]->(Quantity)
‚úÖ **Extract**: (Process)-[increases by]->(Percentage)

**Example Text**: "Organic matter increased by 2.5% over five years."
**Extract**:
- (organic matter, increased by, 2.5% over five years)

## ‚ö†Ô∏è ENTITY QUALITY REQUIREMENTS

### Specificity (CRITICAL)
‚ùå **AVOID VAGUE ENTITIES**:
- "thousands" ‚Üí ‚úÖ "thousands of people"
- "millions" ‚Üí ‚úÖ "millions of humans"
- "the land" ‚Üí ‚úÖ "agricultural land" or "Slovenia" (be specific)
- "the sea" ‚Üí ‚úÖ "ocean ecosystems" or "Mediterranean Sea" (be specific)
- "it" ‚Üí ‚úÖ Resolve to specific entity from context
- "they" ‚Üí ‚úÖ Resolve to specific group from context

### Conciseness
‚úÖ **KEEP ENTITIES CONCISE** (2-5 words typically):
- ‚úÖ GOOD: "soil ecosystem complexity"
- ‚ùå BAD: "hardly anything is as complex as the living web of interconnectedness found in our planet's soil"

### Pronoun Resolution
‚úÖ **RESOLVE PRONOUNS** when context allows:
- "I hail from Slovenia. My people love the land."
  - ‚úÖ BETTER: (Aaron William Perry, hails from, Slovenia)
  - ‚úÖ BETTER: (Slovenians, love, agricultural land)
  - ‚ö†Ô∏è ACCEPTABLE IF UNCLEAR: (my people, love, the land) [will be flagged]

### Entity Specificity Principle
Always prefer SPECIFIC, CONTEXTUALIZED entities over GENERIC ones. Use document context (geographic setting, domain, author background) to add precision.

**Examples of Specific vs. Generic Entities**:
- ‚úÖ "Slovenian countryside" > ‚ùå "the land"
- ‚úÖ "atmospheric carbon dioxide" > ‚ùå "carbon"
- ‚úÖ "regenerative agriculture practices" > ‚ùå "farming"
- ‚úÖ "Bill Mollison's permaculture system" > ‚ùå "the system"
- ‚úÖ "soil microbiome" > ‚ùå "microorganisms"

**Instruction**: When you encounter generic references ("the land", "the process", "the answer"), look at surrounding context to identify the specific entity being referenced. If context is insufficient, skip the relationship rather than extract a vague entity.

## üìö CONTENT TYPE HANDLING

### Content Type Recognition
Distinguish between different types of content to extract appropriately:

**ENDORSEMENT QUOTES**: Praise from reviewers, typically in foreword or back cover
**FACTUAL CONTENT**: Main text describing concepts, processes, or relationships
**AUTHOR CLAIMS**: Author's own statements about their work

### Handling Rules by Content Type

#### From ENDORSEMENT QUOTES:
‚úÖ **Extract ONLY**: (Reviewer, endorsed, Book) relationships
‚ùå **DO NOT extract**: Content claims from praise language
‚ùå **DO NOT extract**: Metaphorical 'is-a' from praise ('is a compass', 'is a road-map', 'is a guide')
‚ùå **DO NOT extract**: Functional claims from promotional language ('this book nourishes soil', 'helps heal the planet')

**Rationale**: Endorsement quotes are promotional opinions, not factual content. They tell us WHO endorsed WHAT, but not factual information about the subject matter.

#### From FACTUAL CONTENT:
‚úÖ **Extract**: All relevant relationships normally following all extraction rules

#### From AUTHOR CLAIMS:
‚úÖ **Extract**: But mark as author's perspective if subjective

### Detection Guidance

**Endorsement Markers**:
- Phrases: "I recommend", "This book is", "I highly encourage", "A must-read"
- Praise adjectives: "wonderful", "essential", "invaluable", "brilliant"
- Reviewer attribution: "‚Äî Name, Title/Organization"
- Recommendation language: "should read", "will benefit from"

**Location Indicators**:
- First 2-3 pages (foreword, introduction)
- Last pages (back matter, praise section)
- Quotation blocks with attribution

**Tone Indicators**:
- Promotional, laudatory, recommendation-focused
- Second-person address ("you will find")
- Superlatives and emphatic language

### Examples

#### ‚ùå WRONG Extractions from Endorsements:
- From "This handbook nourishes the soil" ‚Üí ‚ùå (Handbook, nourishes, soil)
- From "This book is a compass for change" ‚Üí ‚ùå (Book, is-a, compass)
- From "Helps heal the planet" ‚Üí ‚ùå (Book, helps heal, planet)
- From "A road-map to regeneration" ‚Üí ‚ùå (Book, is-a, road-map)

#### ‚úÖ CORRECT Extractions from Endorsements:
- From "This handbook nourishes the soil ‚Äî Brigitte Mars" ‚Üí ‚úÖ (Brigitte Mars, endorsed, Handbook)
- From "This book is a compass for change ‚Äî Joel Salatin" ‚Üí ‚úÖ (Joel Salatin, endorsed, Book)
- From "I highly recommend this work ‚Äî Dr. Elaine Ingham" ‚Üí ‚úÖ (Dr. Elaine Ingham, endorsed, Book)

#### ‚úÖ CORRECT Extractions from Factual Content:
- From main text: "Compost nourishes soil by adding organic matter" ‚Üí ‚úÖ (compost, nourishes, soil by adding organic matter)
- From main text: "This method serves as a guide for farmers" ‚Üí ‚úÖ (method, guides, farmers)
- From main text: "Cover crops help heal degraded soil" ‚Üí ‚úÖ (cover crops, help heal, degraded soil)

### Decision Framework for Content Type:

1. **Is this in a foreword, introduction, or praise section?** ‚Üí Likely ENDORSEMENT
2. **Does it contain recommendation language or praise?** ‚Üí Likely ENDORSEMENT
3. **Is there reviewer attribution?** ‚Üí Definitely ENDORSEMENT
4. **Is this describing how something works or what it contains?** ‚Üí FACTUAL CONTENT
5. **Is the author making claims about their own work?** ‚Üí AUTHOR CLAIMS

**When in doubt**: If the statement sounds promotional or laudatory, treat as endorsement and extract ONLY the endorsement relationship.

## ‚úÖ V11: EXTRACT ALL STATEMENT TYPES (They will be labeled)

Extract ALL relationships including philosophical, normative, and metaphorical statements. They will be properly classified in Pass 2 with flags like:
- FACTUAL (verifiable facts)
- METAPHOR (figurative language)
- PHILOSOPHICAL_CLAIM (essence claims, value judgments)
- TESTABLE_CLAIM (empirical assertions)

The postprocessing pipeline (Pass 2.5) will then handle these appropriately:
- Metaphors: Normalized by FigurativeLanguageFilter
- Philosophical claims: Labeled and flagged
- All relationships: Properly categorized

**Patterns to Extract and Label** (V11 NEW):
- ‚úÖ Philosophical essence claims: 'X is what it means to be Y' ‚Üí Will be labeled PHILOSOPHICAL_CLAIM
- ‚úÖ Normative prescriptions: 'we should/must do X' ‚Üí Will be labeled appropriately
- ‚úÖ Metaphorical abstractions: 'X is the answer/key/solution' ‚Üí Will be labeled METAPHOR
- ‚úÖ Rhetorical constructions: 'X opens doors to Y' ‚Üí Will be labeled METAPHOR
- ‚úÖ Value judgments: 'X is beautiful/important/essential' ‚Üí Will be labeled OPINION/PHILOSOPHICAL_CLAIM
- ‚úÖ All factual statements: 'soil contains organic matter' ‚Üí Will be labeled FACTUAL

**Examples** (V11 - Extract ALL, labels added in Pass 2):
- ‚úÖ EXTRACT: 'being connected to land is what it means to be human' ‚Üí (being connected to land, is what it means to be, human) [Will be labeled PHILOSOPHICAL_CLAIM]
- ‚úÖ EXTRACT: 'soil is the answer' ‚Üí (soil, is, the answer) [Will be labeled METAPHOR and normalized by postprocessing]
- ‚úÖ EXTRACT: 'we must regenerate the soil' ‚Üí (we, must regenerate, soil) [Will be labeled with appropriate classification]
- ‚úÖ EXTRACT: 'soil contains organic matter' ‚Üí (soil, contains, organic matter) [Will be labeled FACTUAL]
- ‚úÖ EXTRACT: 'regenerative agriculture increases soil carbon' ‚Üí (regenerative agriculture, increases, soil carbon) [Will be labeled TESTABLE_CLAIM or FACTUAL]

## ‚úÖ V11: FIGURATIVE LANGUAGE HANDLING

Extract metaphorical statements - they will be labeled as METAPHOR in Pass 2 and normalized by the FigurativeLanguageFilter module in Pass 2.5 postprocessing.

### Common Metaphor Patterns to AVOID:
- ‚ùå 'X is a Y' where Y is figurative: Eden, paradise, crossroads, miracle, answer, key, door, journey, treasure, gold mine
- ‚ùå 'X opens doors to Y' (metaphor for enabling/opportunity)
- ‚ùå 'X is the key to Y' (metaphor for importance/solution)
- ‚ùå 'X is a journey' (metaphor for process/experience)
- ‚ùå 'X is the heart of Y' (metaphor for centrality)
- ‚ùå 'X is a bridge to Y' (metaphor for connection)
- ‚ùå 'X is the foundation of Y' (metaphor for importance) - UNLESS literally structural
- ‚ùå 'X is a window into Y' (metaphor for insight)

### Metaphor Recognition Examples:

**EXTRACT - Pure Metaphor** (V11 NEW - will be labeled METAPHOR):
- ‚úÖ "Our land is a veritable Eden" ‚Üí (our land, is, veritable Eden) [METAPHOR flag, will be normalized]
- ‚úÖ "We are at a crossroads" ‚Üí (we, are at, crossroads) [METAPHOR flag]
- ‚úÖ "Soil is the answer to climate change" ‚Üí (soil, is answer to, climate change) [METAPHOR flag]
- ‚úÖ "This opens doors to new possibilities" ‚Üí (this, opens doors to, new possibilities) [METAPHOR flag]
- ‚úÖ "Knowledge is a treasure" ‚Üí (knowledge, is, treasure) [METAPHOR flag]

**EXTRACT LITERAL - Clear Underlying Fact**:
- ‚úÖ "Soil is the foundation of agriculture" ‚Üí (soil, supports, agriculture) [literal dependency]
- ‚úÖ "Trees provide oxygen" ‚Üí (trees, produce, oxygen) [literal process]
- ‚úÖ "Roots anchor plants in soil" ‚Üí (roots, anchor, plants in soil) [literal function]

**SKIP - Ambiguous/Unclear**:
- ‚ùå "Regeneration is a journey we must take together" (metaphorical framing)
- ‚ùå "This practice is the key to success" (vague metaphor)

### Decision Framework:
1. **Is the statement using figurative/poetic language?** ‚Üí SKIP
2. **Does 'X is Y' use Y as a metaphor (Eden, key, answer, journey)?** ‚Üí SKIP
3. **Can you extract a clear, testable, literal claim?** ‚Üí EXTRACT
4. **When in doubt about metaphor vs. literal?** ‚Üí SKIP (err on side of caution)

## üìö FEW-SHOT EXTRACTION EXAMPLES

### Example 1: Bibliographic Citation (FULL EXTRACTION)
**Input**: "Capra, Fritjof. The Web of Life. New York: Anchor Books, 1996."
**Output**:
- (Fritjof Capra, authored, The Web of Life)
- (The Web of Life, published by, Anchor Books)
- (The Web of Life, published in, New York)
- (The Web of Life, published in, 1996)

### Example 2: Dedication (CONTEXT-AWARE)
**Input**: "Dedicated to my two children, Osha and Hunter, who remind me daily of the importance of caring for our planet."
**Context**: Book authored by Aaron Perry
**Output**:
- (Aaron Perry, dedicated, Soil Stewardship Handbook to Osha)
- (Aaron Perry, dedicated, Soil Stewardship Handbook to Hunter)
- (Osha, reminds, Aaron Perry of importance of caring for planet)
- (Hunter, reminds, Aaron Perry of importance of caring for planet)

### Example 3: Categorical Definition
**Input**: "Biochar is a carbon-rich material produced by heating biomass in low-oxygen conditions."
**Output**:
- (biochar, is-a, carbon-rich material)
- (biochar, produced by, heating biomass in low-oxygen conditions)

### Example 4: Compositional Relationship
**Input**: "This handbook contains chapters on composting, cover cropping, and no-till methods."
**Output**:
- (handbook, contains, chapter on composting)
- (handbook, contains, chapter on cover cropping)
- (handbook, contains, chapter on no-till methods)

### Example 5: Functional Relationship
**Input**: "No-till farming preserves soil structure and enhances water retention."
**Output**:
- (no-till farming, preserves, soil structure)
- (no-till farming, enhances, water retention)

### Example 6: Organizational Affiliation
**Input**: "Dr. Elaine Ingham founded the Soil Food Web School to teach farmers about soil biology."
**Output**:
- (Dr. Elaine Ingham, founded, Soil Food Web School)
- (Soil Food Web School, teaches, farmers about soil biology)

### Example 7: Practical Instructions
**Input**: "Choose appropriate seasons and species best suited for your region."
**Output**:
- (farmers, should choose, appropriate seasons for planting)
- (farmers, should choose, species suited for region)

### Example 8: Scientific Facts (TESTABLE CLAIM)
**Input**: "Mycorrhizal fungi form symbiotic relationships with plant roots, enhancing nutrient uptake."
**Output**:
- (mycorrhizal fungi, form symbiosis with, plant roots)
- (mycorrhizal fungi, enhance, nutrient uptake)

### Example 9: Philosophical Statement (EXTRACT AND LABEL - V11 NEW)
**Input**: "Being connected to land and soil is what it means to be human."
**Output**:
- (being connected to land and soil, is what it means to be, human)
- [Will be labeled PHILOSOPHICAL_CLAIM in Pass 2, flagged appropriately]

### Example 10: Metaphorical Language (EXTRACT AND LABEL - V11 NEW)
**Input**: "Our land has remained a veritable Eden through the ages."
**Output**:
- (our land, remained, veritable Eden through ages)
- [Will be labeled METAPHOR in Pass 2, normalized by FigurativeLanguageFilter]

### Example 11: Figurative Language (EXTRACT AND LABEL - V11 NEW)
**Input**: "This approach opens doors to sustainable farming practices."
**Output**:
- (this approach, enables, sustainable farming practices)
- [Extracted with normalized relationship, will be labeled appropriately]

### Example 12: Metaphor with Literal Meaning (EXTRACT LITERAL)
**Input**: "Soil is the foundation of all terrestrial ecosystems, providing nutrients and structure."
**Output**:
- (soil, provides nutrients to, terrestrial ecosystems)
- (soil, provides structure to, terrestrial ecosystems)
- NOTE: "foundation" here has literal functional meaning, extract the specific functions

### Example 13: Endorsement Quote (EXTRACT ONLY ENDORSEMENT)
**Input**: "This handbook is a treasure trove of wisdom that will nourish your soil and heal the planet. I highly recommend it! ‚Äî Brigitte Mars, herbalist and author"
**Output**:
- (Brigitte Mars, endorsed, Soil Stewardship Handbook)
- NOTE: Do NOT extract (handbook, is-a, treasure trove) or (handbook, nourishes, soil) - these are promotional metaphors

### Example 14: Endorsement vs. Factual Content
**Input Endorsement**: "This book is a compass guiding us toward regeneration. ‚Äî Joel Salatin"
**Output**:
- (Joel Salatin, endorsed, Book)

**Input Factual**: "This compass uses magnetic north to guide navigation."
**Output**:
- (compass, uses, magnetic north)
- (compass, guides, navigation)

## üìù OUTPUT FORMAT

For each relationship provide:
- **source**: Concise source entity (2-5 words, NO pronouns, NO vague quantifiers)
- **relationship**: Relationship type (authored, published by, contains, is-a, produces, enhances, etc.)
- **target**: Concise target entity (2-5 words, NO pronouns, NO vague quantifiers)
- **evidence_text**: Quote from text (100-300 characters)

## üìñ TEXT TO EXTRACT FROM

{text}

## ‚ö° BE COMPREHENSIVE, SPECIFIC, AND ACCURATE

Extract relationships that are:
- ‚úÖ **COMPREHENSIVE**: Extract ALL valuable factual relationships (bibliographic, categorical, compositional, functional, organizational)
- ‚úÖ **SPECIFIC**: Avoid vague entities ("thousands" ‚Üí "thousands of people", "the land" ‚Üí "agricultural land")
- ‚úÖ **ACCURATE**: Clearly stated or strongly implied in the text
- ‚úÖ **MEANINGFUL**: Useful for building a complete general knowledge graph (not discourse graph)
- ‚úÖ **CONCISE**: Use 2-5 word entities when possible
- ‚úÖ **CONTENT-AWARE**: Distinguish endorsements from factual content - extract only endorsement relationships from praise sections
- ‚úÖ **V11 APPROACH**: Extract ‚Üí Label in Pass 2 ‚Üí Normalize in Pass 2.5 ‚Üí Properly classified output

**PRIORITY**: Bibliographic citations, categorical definitions, compositional relationships, functional relationships, and organizational affiliations are HIGH VALUE. Extract ALL of them.

**QUALITY TIPS** (V11 Updated):
- Resolve pronouns to specific entities when context allows
- Be specific with determiners and quantifiers ("the land" ‚Üí "agricultural land")
- Extract ALL relationships including philosophical, metaphorical, and normative statements (they will be labeled)
- DO extract figurative language - it will be labeled as METAPHOR and normalized in postprocessing
- When in doubt, DO extract - Pass 2 and Pass 2.5 will handle classification and normalization
- Bibliographic citations are NOT "too simple" - they are ESSENTIAL knowledge graph elements
- From endorsement quotes, extract ONLY endorsement relationships, NOT content claims
- V11 philosophy: Extract comprehensively, label properly, process intelligently

# V14 ENHANCEMENTS

## ENTITY SPECIFICITY CONSTRAINTS

Extract specific, concrete entities only. Avoid abstract philosophical terms unless they are well-defined concepts.

**FORBIDDEN ENTITY PATTERNS** (Do NOT extract):
- Demonstrative pronouns without clear resolution: Extract 'this', 'that', 'these', 'those' if context is clear; allow postprocessing to resolve them. Skip only if ambiguous.
- Abstract philosophical terms: 'the answer', 'the way', 'the solution'
- Vague generalizations: 'aspects of life', 'the process', 'things', 'matters'

Note: Allow compound phrases if they provide specific context (e.g., "productively vital states" is acceptable)

If an entity is abstract, try to identify the specific concept it refers to in context.

**GOOD vs BAD Examples**:
‚ùå BAD: "soil stewardship" ‚Üí "affects" ‚Üí "aspects of life"  (too vague)
‚úÖ GOOD: "soil stewardship" ‚Üí "affects" ‚Üí "human health and agriculture"  (specific)

‚ùå BAD: "this approach" ‚Üí "enables" ‚Üí "sustainable farming"  (demonstrative pronoun)
‚úÖ GOOD: "soil stewardship" ‚Üí "enables" ‚Üí "sustainable farming"  (resolved)

## SEMANTIC PREDICATE VALIDATION

Ensure predicates are semantically appropriate for the entity types. The predicate should express a logical relationship.

**Examples of correct vs incorrect predicates**:
‚ùå BAD: "soil" ‚Üí "collapses" ‚Üí "humanity"  (semantically odd)
‚úÖ GOOD: "soil degradation" ‚Üí "threatens" ‚Üí "humanity"  (semantically correct)

Use precise, semantically correct verbs that match the nature of the entities.

# V14.2 ENTITY RESOLUTION (NEW)

## DEMONSTRATIVE PRONOUN RESOLUTION

When you encounter demonstrative pronouns ("this", "that", "these", "those"), **look back 1-3 sentences** to identify what they refer to and extract using the specific entity.

**Resolution Process**:
1. Identify the demonstrative pronoun
2. Look at the previous 1-3 sentences for context
3. Find the most recent specific concept or entity that matches
4. Extract using the resolved specific entity

**Examples of CORRECT Resolution**:

**Input**: "Soil stewardship is essential for sustainability. This approach opens doors to sustainable farming practices."
‚úÖ **Extract**: (soil stewardship, enables, sustainable farming practices)
‚ùå **Don't Extract**: (this approach, enables, sustainable farming practices)

**Input**: "The connection with the soil has been preserved in the Slovenian countryside. Their land remains productive."
‚úÖ **Extract**: (connection with soil, preserved in, Slovenian countryside)
‚úÖ **Extract**: (Slovenian countryside, remains, productive)
‚ùå **Don't Extract**: (their land, remains, productive)

**Input**: "Regenerative agriculture practices build soil health. These methods restore degraded agricultural soils to productively vital states."
‚úÖ **Extract**: (regenerative agriculture practices, restore, degraded agricultural soils to productively vital states)
‚ùå **Don't Extract**: (these methods, restore, degraded agricultural soils)

## PRONOUN RESOLUTION

Resolve personal and possessive pronouns to specific entities when context is clear.

**Common Pronoun Patterns**:

**"We/Us" ‚Üí Resolve to specific group**:
- Context about humanity/humans ‚Üí Extract as "humanity" or "humans"
- Context about farmers ‚Üí Extract as "farmers"
- Context about specific community ‚Üí Extract as that community name

**"They/Their/Them" ‚Üí Resolve to previously mentioned group**:
- Look back 1-2 sentences for the antecedent
- Use the specific group name

**"It/Its" ‚Üí Resolve to previously mentioned entity**:
- Look back 1-2 sentences for the antecedent
- Use the specific entity name

**Examples**:

**Input**: "By reconnecting with the land, we can heal. Humanity must establish this connection."
‚úÖ **Extract**: (humanity, can heal by, reconnecting with land)
‚úÖ **Extract**: (humanity, must establish, connection with land)
‚ùå **Don't Extract**: (we, can heal, by reconnecting)

**Input**: "Soil contains microorganisms. It heals humans through microbial exposure."
‚úÖ **Extract**: (soil, contains, microorganisms)
‚úÖ **Extract**: (soil, heals, humans through microbial exposure)
‚ùå **Don't Extract**: (it, heals, humans)

**Input**: "Individuals can cultivate their own human potential by working with soil."
‚úÖ **Extract**: (individuals, can cultivate, human potential by working with soil)
‚ùå **Don't Extract**: (individuals, can cultivate, their own human potential)

# V14.2 SEMANTIC ABSTRACTION (NEW)

## CONVERTING RHETORICAL LANGUAGE TO FACTUAL CLAIMS

When you encounter rhetorical or philosophical phrasing, extract the **underlying factual claim** by converting dramatic language to measured statements.

**Common Rhetorical Patterns to Convert**:

### "X is the answer to Y" ‚Üí "X can help with Y" or "X addresses Y"

**Input**: "Soil is the answer to climate change."
‚úÖ **Extract**: (soil management, can help address, climate change)
‚ùå **Don't Extract**: (soil, is answer to, climate change)

**Rationale**: "Is the answer" is rhetorical emphasis. Extract the factual relationship: soil management practices can help mitigate climate change.

### "X is the foundation of Y" ‚Üí "X supports Y" or "X is basis for Y"

**Input**: "Soil is the foundation of human life."
‚úÖ **Extract**: (soil, is basis for, human life)
‚úÖ **Extract**: (soil, supports, agriculture and food production)
‚ùå **Don't Extract**: (soil, is, foundation of human life) [too literal on metaphor]

**Rationale**: Extract the functional relationship, not the metaphorical phrasing.

### "X threatens Y" ‚Üí "X may harm Y" or "X endangers Y"

**Input**: "Soil degradation threatens humanity."
‚úÖ **Extract**: (soil degradation, threatens, humanity)
‚ùå **Don't Extract**: (soil degradation, collapses, humanity) [wrong predicate]

**Rationale**: "Threatens" is semantically correct. "Collapses" would be semantically odd with "humanity" as target.

### "X is-a [metaphorical term]" ‚Üí Identify the functional relationship

**Input**: "This book is a compass guiding us toward regeneration."
‚úÖ **Extract**: (book, guides toward, regeneration) [IF in factual content]
‚úÖ **Extract**: (Author, endorsed, book) [IF in endorsement quote]
‚ùå **Don't Extract**: (book, is-a, compass)

### Decision Framework for Rhetorical Language

1. **Is the phrasing dramatic or emphatic?** ‚Üí Look for the factual claim underneath
2. **Can you identify a specific, measurable relationship?** ‚Üí Extract that
3. **Would a scientist accept this phrasing?** ‚Üí If no, abstract to factual form
4. **Does the predicate contain "answer", "key", "foundation" metaphorically?** ‚Üí Convert to functional predicate

# V14.2 COMPLEX PARSING (NEW)

## HANDLING MULTI-CLAUSE SENTENCES

When you encounter verbose sentences with multiple clauses, extract each distinct relationship separately.

**Parsing Strategy**:
1. Identify the main subject
2. Identify each distinct action/effect
3. Extract each as a separate relationship
4. Preserve hedging language ("may", "can", "could") in predicates

**Example 1: List of Effects**

**Input**: "By getting our hands in the living dirt, we literally soothe the anxieties of daily stress, enhance our immune systems, and increase our production of serotonin."

‚úÖ **Extract**:
- (getting hands in soil, may soothe, anxieties from daily stress)
- (getting hands in soil, may enhance, immune systems)
- (getting hands in soil, may increase, serotonin production)

**Rationale**: Three distinct effects, extract each separately. Add "may" to preserve appropriate confidence level for testable claims.

**Example 2: Multiple Predicates**

**Input**: "Cover cropping enhances soil structure, prevents erosion, and sequesters atmospheric carbon."

‚úÖ **Extract**:
- (cover cropping, enhances, soil structure)
- (cover cropping, prevents, erosion)
- (cover cropping, sequesters, atmospheric carbon)

**Example 3: Nested Context**

**Input**: "Through regenerative soil management practices like composting and no-till farming, we can mitigate climate change by sequestering carbon."

‚úÖ **Extract**:
- (regenerative soil management practices, can mitigate, climate change)
- (composting, is type of, regenerative soil management)
- (no-till farming, is type of, regenerative soil management)
- (carbon sequestration, is mechanism for, climate change mitigation)

**Rationale**: Break down the complex statement into specific relationships. Don't try to capture everything in one relationship.

## HANDLING AWKWARD PHRASING

When source text has awkward grammar or phrasing, normalize to grammatically correct relationships.

**Input**: "Agricultural soils restores productively vital states."
‚úÖ **Extract**: (regenerative practices, restore, agricultural soils to productively vital states)
‚ùå **Don't Extract**: (agricultural soils, restores, productively vital states) [grammatically incorrect]

**Rationale**: Fix obvious grammatical errors. "Soils" (plural) can't "restores" (singular verb). Infer the intended meaning.

## V14.2 SUMMARY

The V14.2 improvements add three critical capabilities:

1. **Entity Resolution**: Resolve demonstrative and personal pronouns by looking back 1-3 sentences
2. **Semantic Abstraction**: Convert rhetorical language ("is the answer", "is the foundation") to factual claims
3. **Complex Parsing**: Break multi-clause sentences into separate relationships, preserve hedging

These improvements specifically address test cases TC004-TC017 which require context understanding, semantic abstraction, and complex parsing.
