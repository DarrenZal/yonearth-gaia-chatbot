{
  "changeset_metadata": {
    "source_version": "v7_meta_ace",
    "target_version": "v8_production_ready",
    "total_changes": 15,
    "estimated_impact": "Reduces critical issues by 100% (4\u21920), high priority by 89% (12\u21922), total issues from 6.71% to ~2.8%",
    "production_readiness": "After V8, system meets <5% issue rate threshold for production deployment"
  },
  "file_operations": [
    {
      "operation_id": "change_001",
      "operation_type": "NEW_MODULE",
      "file_path": "modules/pass2_5_postprocessing/praise_quote_detector.py",
      "priority": "CRITICAL",
      "rationale": "Eliminates all 4 reversed authorship errors (0.43%). Praise quotes in front matter are being misidentified as authorship claims. Need dedicated detector to run BEFORE bibliographic parser.",
      "risk_level": "low",
      "affected_issue_category": "Reversed Authorship (Praise Quotes)",
      "expected_improvement": "Fixes 4/4 critical reversed authorship errors (100% resolution)",
      "create_details": {
        "module_name": "PraiseQuoteDetector",
        "class_template": "PostProcessingModule",
        "dependencies": [
          "re",
          "typing",
          "dataclasses"
        ],
        "content": "import re\nfrom typing import List, Dict, Tuple\nfrom dataclasses import dataclass\n\n@dataclass\nclass PraiseQuotePattern:\n    \"\"\"Pattern for detecting praise quotes in front matter.\"\"\"\n    person_name_pattern: str = r'\u2014([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+)'\n    credentials_pattern: str = r'(?:Founding|Director|Chair|Professor|PhD|Author|Champion)'\n    authorship_verbs: List[str] = None\n    \n    def __post_init__(self):\n        if self.authorship_verbs is None:\n            self.authorship_verbs = ['authored', 'wrote', 'written by', 'author of']\n\nclass PraiseQuoteDetector:\n    \"\"\"Detects and corrects praise quotes misidentified as authorship.\n    \n    Praise quotes appear in front matter with pattern:\n    - Quote text mentioning book/author\n    - Attribution: \u2014Name\n    - Credentials: Title, Organization\n    \n    These should be (Endorser, endorsed, Book) not (Endorser, authored, Book).\n    \"\"\"\n    \n    def __init__(self):\n        self.pattern = PraiseQuotePattern()\n        self.front_matter_pages = range(1, 15)  # Typical front matter range\n        self.endorsement_indicators = [\n            'inspirational', 'beautifully-informed', 'wonderful',\n            'informative handbook', 'gives us', 'invites us'\n        ]\n        \n    def is_praise_quote_context(self, evidence_text: str, page: int) -> bool:\n        \"\"\"Check if evidence suggests praise quote rather than authorship.\"\"\"\n        if page not in self.front_matter_pages:\n            return False\n            \n        # Check for attribution marker\n        has_attribution = bool(re.search(self.pattern.person_name_pattern, evidence_text))\n        \n        # Check for credentials (not typical in authorship claims)\n        has_credentials = bool(re.search(self.pattern.credentials_pattern, evidence_text))\n        \n        # Check for endorsement language\n        has_endorsement_language = any(\n            indicator in evidence_text.lower() \n            for indicator in self.endorsement_indicators\n        )\n        \n        return has_attribution or has_credentials or has_endorsement_language\n    \n    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Process relationships to detect and correct praise quote misattributions.\"\"\"\n        corrected = []\n        \n        for rel in relationships:\n            relationship_type = rel.get('relationship', '').lower()\n            evidence = rel.get('evidence_text', '')\n            page = rel.get('page', 0)\n            \n            # Check if this is authorship claim in praise quote context\n            if any(verb in relationship_type for verb in self.pattern.authorship_verbs):\n                if self.is_praise_quote_context(evidence, page):\n                    # Correct to endorsement\n                    rel['relationship'] = 'endorsed'\n                    rel['quality_flags'] = rel.get('quality_flags', []) + ['PRAISE_QUOTE_CORRECTED']\n                    rel['correction_note'] = 'Changed from authorship to endorsement (praise quote detected)'\n            \n            corrected.append(rel)\n        \n        return corrected",
        "integration_point": "orchestrator.py:pass_2_5_quality_post_processing",
        "integration_order": "FIRST (before BibliographicCitationParser)",
        "validation": "Unit tests with all 4 V7 praise quote examples"
      }
    },
    {
      "operation_id": "change_002",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/pronoun_resolver.py",
      "priority": "CRITICAL",
      "rationale": "Fixes 18 pronoun issues (8 unresolved + 10 possessive = 1.95%). Current resolver flags pronouns but doesn't resolve them. Need coreference resolution with expanded context window.",
      "risk_level": "medium",
      "affected_issue_category": "Unresolved Pronouns (Source) + Possessive Pronouns (Source)",
      "expected_improvement": "Fixes 18/18 pronoun errors (100% resolution), reduces issue rate by 1.95%",
      "edit_details": {
        "target_function": "PronounResolver.__init__",
        "old_content": "    def __init__(self):\n        self.pronouns = ['he', 'she', 'they', 'it', 'we']\n        self.context_window = 1  # sentences",
        "new_content": "    def __init__(self):\n        self.pronouns = ['he', 'she', 'they', 'it', 'we', 'you']\n        self.possessive_pronouns = ['my', 'our', 'your', 'their', 'his', 'her', 'its']\n        self.possessive_patterns = [\n            r'\\b(my|our|your|their)\\s+(people|ancestors|family|community)\\b',\n            r'\\b(my|our|your|their)\\s+(\\w+)\\b'  # Generic possessive\n        ]\n        self.context_window = 5  # Expanded to 5 sentences for better antecedent lookup\n        self.author_context = None  # Will be set from document metadata",
        "validation": "Test with V7 examples: 'my people' \u2192 'Slovenians', 'we' \u2192 'humanity'"
      }
    },
    {
      "operation_id": "change_003",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/pronoun_resolver.py",
      "priority": "CRITICAL",
      "rationale": "Add possessive pronoun resolution logic. Current code only handles subject pronouns.",
      "risk_level": "medium",
      "affected_issue_category": "Possessive Pronouns (Source)",
      "expected_improvement": "Enables resolution of 10 possessive pronoun cases",
      "edit_details": {
        "target_function": "PronounResolver.resolve_pronoun",
        "old_content": "    def resolve_pronoun(self, pronoun: str, context: str) -> str:\n        \"\"\"Resolve pronoun to entity using context.\"\"\"\n        if pronoun.lower() not in self.pronouns:\n            return pronoun\n        \n        # Simple fallback to generic\n        generic_map = {\n            'we': 'humanity',\n            'you': 'readers',\n            'they': 'people'\n        }\n        return generic_map.get(pronoun.lower(), pronoun)",
        "new_content": "    def resolve_pronoun(self, pronoun: str, context: str, page: int = 0) -> Tuple[str, str]:\n        \"\"\"Resolve pronoun to entity using context and document metadata.\n        \n        Returns: (resolved_entity, resolution_method)\n        \"\"\"\n        pronoun_lower = pronoun.lower()\n        \n        # Handle possessive pronouns first\n        for pattern in self.possessive_patterns:\n            match = re.search(pattern, pronoun_lower)\n            if match:\n                possessive, noun = match.groups() if len(match.groups()) == 2 else (match.group(1), None)\n                \n                # Context-specific resolution\n                if 'slovenia' in context.lower() or 'slovenian' in context.lower():\n                    if noun in ['people', 'ancestors', 'family']:\n                        return ('Slovenians', 'CONTEXT_RESOLVED')\n                \n                # Author-specific resolution\n                if self.author_context and possessive in ['my', 'our']:\n                    if noun == 'people':\n                        return (f\"{self.author_context}'s people\", 'AUTHOR_CONTEXT_RESOLVED')\n                \n                # Generic possessive resolution\n                if noun:\n                    return (f\"the {noun}\", 'GENERIC_POSSESSIVE_RESOLVED')\n        \n        # Handle subject pronouns\n        if pronoun_lower not in self.pronouns:\n            return (pronoun, 'NOT_PRONOUN')\n        \n        # Context-based resolution with expanded window\n        sentences = self._get_context_sentences(context, window=self.context_window)\n        \n        # Look for named entities in context\n        entities = self._extract_entities_from_context(sentences)\n        if entities:\n            # Use most recent entity as antecedent\n            return (entities[-1], 'ANTECEDENT_RESOLVED')\n        \n        # Fallback to generic with better mapping\n        generic_map = {\n            'we': 'humanity',\n            'you': 'readers', \n            'they': 'people',\n            'he': 'he',  # Keep if no antecedent found\n            'she': 'she',\n            'it': 'it'\n        }\n        return (generic_map.get(pronoun_lower, pronoun), 'GENERIC_RESOLVED')\n    \n    def _get_context_sentences(self, context: str, window: int = 5) -> List[str]:\n        \"\"\"Extract sentences from context.\"\"\"\n        import re\n        sentences = re.split(r'[.!?]+', context)\n        return [s.strip() for s in sentences if s.strip()][-window:]\n    \n    def _extract_entities_from_context(self, sentences: List[str]) -> List[str]:\n        \"\"\"Extract named entities from context sentences.\"\"\"\n        entities = []\n        # Simple capitalized word detection (can be enhanced with NER)\n        for sentence in sentences:\n            words = sentence.split()\n            for word in words:\n                if word and word[0].isupper() and len(word) > 1:\n                    if word not in ['The', 'A', 'An', 'In', 'On', 'At', 'To', 'For']:\n                        entities.append(word)\n        return entities",
        "validation": "Test with: 'my people' in Slovenia context \u2192 'Slovenians', 'we' with no context \u2192 'humanity'"
      }
    },
    {
      "operation_id": "change_004",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/pronoun_resolver.py",
      "priority": "CRITICAL",
      "rationale": "Update process_batch to use new resolution logic and set author context from metadata.",
      "risk_level": "medium",
      "affected_issue_category": "Unresolved Pronouns (Source) + Possessive Pronouns (Source)",
      "expected_improvement": "Enables full pronoun resolution pipeline",
      "edit_details": {
        "target_function": "PronounResolver.process_batch",
        "old_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Process batch of relationships to resolve pronouns.\"\"\"\n        resolved = []\n        for rel in relationships:\n            source = rel.get('source', '')\n            if source.lower() in self.pronouns:\n                context = rel.get('evidence_text', '')\n                resolved_source = self.resolve_pronoun(source, context)\n                rel['source'] = resolved_source\n                rel['quality_flags'] = rel.get('quality_flags', []) + ['PRONOUN_RESOLVED']\n            resolved.append(rel)\n        return resolved",
        "new_content": "    def process_batch(self, relationships: List[Dict], document_metadata: Dict = None) -> List[Dict]:\n        \"\"\"Process batch of relationships to resolve pronouns.\n        \n        Args:\n            relationships: List of relationship dicts\n            document_metadata: Optional metadata with author info\n        \"\"\"\n        # Set author context from metadata\n        if document_metadata:\n            self.author_context = document_metadata.get('author', None)\n        \n        resolved = []\n        for rel in relationships:\n            source = rel.get('source', '')\n            context = rel.get('evidence_text', '')\n            page = rel.get('page', 0)\n            \n            # Check if source contains pronoun (including possessive patterns)\n            needs_resolution = (\n                source.lower() in self.pronouns or\n                any(re.search(pattern, source.lower()) for pattern in self.possessive_patterns)\n            )\n            \n            if needs_resolution:\n                resolved_source, method = self.resolve_pronoun(source, context, page)\n                \n                if resolved_source != source:\n                    rel['source'] = resolved_source\n                    rel['quality_flags'] = rel.get('quality_flags', []) + [f'PRONOUN_RESOLVED_{method}']\n                    rel['original_source'] = source\n                else:\n                    # Flag as unresolved if resolution failed\n                    rel['quality_flags'] = rel.get('quality_flags', []) + ['PRONOUN_UNRESOLVED_SOURCE']\n            \n            resolved.append(rel)\n        return resolved",
        "validation": "Integration test with full V7 dataset, check all 18 pronoun cases"
      }
    },
    {
      "operation_id": "change_005",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/vague_entity_detector.py",
      "priority": "HIGH",
      "rationale": "Fixes 8 vague target issues (0.87%). Current detector only flags vague entities but doesn't replace them with specific ones from context.",
      "risk_level": "low",
      "affected_issue_category": "Vague Targets",
      "expected_improvement": "Fixes 8/8 vague target errors (100% resolution)",
      "edit_details": {
        "target_function": "VagueEntityDetector.__init__",
        "old_content": "    def __init__(self):\n        self.vague_patterns = [\n            r'\\bthis\\b', r'\\bthat\\b', r'\\bthese\\b', r'\\bthose\\b',\n            r'\\bthe answer\\b', r'\\bthe way\\b'\n        ]",
        "new_content": "    def __init__(self):\n        self.vague_patterns = [\n            r'\\bthis\\b', r'\\bthat\\b', r'\\bthese\\b', r'\\bthose\\b',\n            r'\\bthe answer\\b', r'\\bthe way\\b', r'\\bthis wonderful place\\b'\n        ]\n        \n        # Mapping of vague terms to specific replacements based on context\n        self.context_replacements = {\n            'this wonderful place': {\n                'keywords': ['earth', 'planet', 'world', 'lives depend'],\n                'replacement': 'Earth'\n            },\n            'the answer': {\n                'keywords': ['soil', 'stewardship', 'questions'],\n                'replacement': 'soil stewardship',\n                'check_motto': True  # Special handling for mottos\n            },\n            'the way': {\n                'keywords': ['forward', 'path', 'direction'],\n                'replacement': 'the path forward'\n            },\n            'this': {\n                'keywords': ['book', 'handbook', 'guide'],\n                'replacement': 'Soil Stewardship Handbook'\n            }\n        }",
        "validation": "Test with V7 examples: 'this wonderful place' \u2192 'Earth'"
      }
    },
    {
      "operation_id": "change_006",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/vague_entity_detector.py",
      "priority": "HIGH",
      "rationale": "Add context-aware replacement logic to actually fix vague entities, not just flag them.",
      "risk_level": "low",
      "affected_issue_category": "Vague Targets",
      "expected_improvement": "Enables vague entity replacement with context-specific terms",
      "edit_details": {
        "target_function": "VagueEntityDetector.process_batch",
        "old_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Flag vague entities.\"\"\"\n        flagged = []\n        for rel in relationships:\n            target = rel.get('target', '')\n            if any(re.search(pattern, target.lower()) for pattern in self.vague_patterns):\n                rel['quality_flags'] = rel.get('quality_flags', []) + ['VAGUE_TARGET']\n            flagged.append(rel)\n        return flagged",
        "new_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Detect and replace vague entities with context-specific terms.\"\"\"\n        processed = []\n        \n        for rel in relationships:\n            target = rel.get('target', '')\n            source = rel.get('source', '')\n            evidence = rel.get('evidence_text', '').lower()\n            relationship = rel.get('relationship', '').lower()\n            \n            # Check each vague pattern\n            for pattern in self.vague_patterns:\n                if re.search(pattern, target.lower()):\n                    # Try to find specific replacement\n                    replacement = self._find_replacement(target, evidence, relationship)\n                    \n                    if replacement and replacement != target:\n                        rel['target'] = replacement\n                        rel['quality_flags'] = rel.get('quality_flags', []) + ['VAGUE_TARGET_RESOLVED']\n                        rel['original_target'] = target\n                    else:\n                        # Flag as vague if no replacement found\n                        rel['quality_flags'] = rel.get('quality_flags', []) + ['VAGUE_TARGET']\n                    break\n            \n            processed.append(rel)\n        return processed\n    \n    def _find_replacement(self, vague_term: str, evidence: str, relationship: str) -> str:\n        \"\"\"Find context-appropriate replacement for vague term.\"\"\"\n        vague_lower = vague_term.lower()\n        \n        # Check each replacement rule\n        for pattern, rule in self.context_replacements.items():\n            if pattern in vague_lower:\n                # Check if context keywords present\n                if any(keyword in evidence for keyword in rule['keywords']):\n                    # Special handling for mottos\n                    if rule.get('check_motto') and 'motto' not in relationship:\n                        return rule['replacement']\n                    elif not rule.get('check_motto'):\n                        return rule['replacement']\n        \n        return vague_term  # Return original if no replacement found",
        "validation": "Test all 8 V7 vague target examples"
      }
    },
    {
      "operation_id": "change_007",
      "operation_type": "PROMPT_ENHANCEMENT",
      "file_path": "prompts/pass2_evaluation_prompt.txt",
      "priority": "HIGH",
      "rationale": "Filters 6 philosophical statements (0.65%). Pass 2 evaluator needs guidance to downweight abstract/philosophical claims that don't convey concrete information.",
      "risk_level": "low",
      "affected_issue_category": "Philosophical/Abstract Statements",
      "expected_improvement": "Filters 6/6 philosophical statements (100% resolution)",
      "edit_details": {
        "target_section": "EVALUATION CRITERIA",
        "old_content": "## EVALUATION CRITERIA\n\n1. **Text Confidence**: Does the evidence text clearly support the relationship?\n2. **Knowledge Plausibility**: Is the relationship factually plausible?\n3. **Specificity**: Are entities specific and well-defined?",
        "new_content": "## EVALUATION CRITERIA\n\n1. **Text Confidence**: Does the evidence text clearly support the relationship?\n2. **Knowledge Plausibility**: Is the relationship factually plausible?\n3. **Specificity**: Are entities specific and well-defined?\n4. **Factual Concreteness**: Does the relationship convey concrete, verifiable information?\n\n### DOWNWEIGHT ABSTRACT/PHILOSOPHICAL STATEMENTS\n\n**Abstract statements to filter:**\n- Philosophical definitions (e.g., \"being connected to land is what it means to be human\")\n- Spiritual/metaphysical claims (e.g., \"spiritual flourishing depends on earth care\")\n- Subjective value judgments without factual basis\n- Existential or ontological statements\n\n**Examples of what to REJECT:**\n\u274c (being connected to land, is what it means to be, human) - philosophical definition\n\u274c (spiritual flourishing, depends on, how we care for earth) - metaphysical claim\n\u274c (humanity's essence, is tied to, soil connection) - abstract ontology\n\n**Examples of what to ACCEPT:**\n\u2705 (Aaron Perry, authored, Soil Stewardship Handbook) - concrete factual claim\n\u2705 (Slovenia, has tradition of, family farming) - verifiable cultural fact\n\u2705 (soil health, affects, crop yields) - concrete causal relationship\n\n**Guideline**: Focus on extracting relationships that could be verified through observation, documentation, or empirical evidence. Philosophical musings and spiritual reflections, while meaningful, are not suitable for a factual knowledge graph.",
        "validation": "Test on V7 philosophical examples, ensure they score low confidence"
      }
    },
    {
      "operation_id": "change_008",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/list_splitter.py",
      "priority": "HIGH",
      "rationale": "Fixes 4 incomplete list splits (0.43%). Current splitter only handles commas, misses 'A, B and C' patterns.",
      "risk_level": "low",
      "affected_issue_category": "Incomplete List Splitting",
      "expected_improvement": "Fixes 4/4 incomplete list splits (100% resolution)",
      "edit_details": {
        "target_function": "ListSplitter.__init__",
        "old_content": "    def __init__(self):\n        self.list_patterns = [\n            r'([^,]+),\\s*([^,]+)',  # Simple comma separation\n        ]",
        "new_content": "    def __init__(self):\n        self.list_patterns = [\n            # Pattern 1: A, B, and C (Oxford comma)\n            r'([^,]+),\\s*([^,]+),\\s*and\\s+([^,]+)',\n            # Pattern 2: A, B and C (no Oxford comma)\n            r'([^,]+),\\s*([^,]+)\\s+and\\s+([^,]+)',\n            # Pattern 3: A and B (simple conjunction)\n            r'([^,]+)\\s+and\\s+([^,]+)',\n            # Pattern 4: A, B (simple comma)\n            r'([^,]+),\\s*([^,]+)',\n        ]",
        "validation": "Test with 'communities and planet' \u2192 ['communities', 'planet']"
      }
    },
    {
      "operation_id": "change_009",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/list_splitter.py",
      "priority": "HIGH",
      "rationale": "Update splitting logic to handle multi-item lists with 'and' conjunction.",
      "risk_level": "low",
      "affected_issue_category": "Incomplete List Splitting",
      "expected_improvement": "Enables splitting of 'A, B and C' patterns",
      "edit_details": {
        "target_function": "ListSplitter.split_target",
        "old_content": "    def split_target(self, target: str) -> List[str]:\n        \"\"\"Split comma-separated target into multiple targets.\"\"\"\n        if ',' in target:\n            return [t.strip() for t in target.split(',')]\n        return [target]",
        "new_content": "    def split_target(self, target: str) -> List[str]:\n        \"\"\"Split target into multiple targets using comma and 'and' patterns.\"\"\"\n        # Try each pattern in order (most specific first)\n        for pattern in self.list_patterns:\n            match = re.match(pattern, target.strip())\n            if match:\n                items = [item.strip() for item in match.groups()]\n                # Filter out empty items\n                return [item for item in items if item]\n        \n        # No pattern matched, return as-is\n        return [target]",
        "validation": "Test: 'families, communities and planet' \u2192 ['families', 'communities', 'planet']"
      }
    },
    {
      "operation_id": "change_010",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/predicate_normalizer.py",
      "priority": "MEDIUM",
      "rationale": "Fixes 2 wrong predicate errors (0.22%). Books don't 'heal' - need semantic validation against entity types.",
      "risk_level": "low",
      "affected_issue_category": "Wrong Predicate Semantics",
      "expected_improvement": "Fixes 2/2 wrong predicate errors (100% resolution)",
      "edit_details": {
        "target_function": "PredicateNormalizer.__init__",
        "old_content": "    def __init__(self):\n        self.predicate_map = {\n            'is a': 'is',\n            'are': 'is',\n        }",
        "new_content": "    def __init__(self):\n        self.predicate_map = {\n            'is a': 'is',\n            'are': 'is',\n        }\n        \n        # Entity type constraints for semantic validation\n        self.entity_type_predicates = {\n            'Book': {\n                'allowed': ['guides', 'informs', 'describes', 'explains', 'teaches', \n                           'provides', 'presents', 'covers', 'discusses', 'authored by'],\n                'forbidden': ['heals', 'cures', 'fixes', 'repairs', 'treats'],\n                'replacements': {\n                    'heals': 'guides readers to heal',\n                    'helps heal': 'provides guidance for healing',\n                    'cures': 'provides information about curing',\n                    'fixes': 'provides solutions for'\n                }\n            },\n            'Person': {\n                'allowed': ['wrote', 'authored', 'created', 'founded', 'established',\n                           'teaches', 'researches', 'studies', 'works on'],\n                'forbidden': [],\n                'replacements': {}\n            }\n        }",
        "validation": "Test: (Book, helps heal, planet) \u2192 (Book, provides guidance for healing, planet)"
      }
    },
    {
      "operation_id": "change_011",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/predicate_normalizer.py",
      "priority": "MEDIUM",
      "rationale": "Add semantic validation logic to check predicate compatibility with entity types.",
      "risk_level": "low",
      "affected_issue_category": "Wrong Predicate Semantics",
      "expected_improvement": "Enables semantic predicate validation",
      "edit_details": {
        "target_function": "PredicateNormalizer.process_batch",
        "old_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Normalize predicates.\"\"\"\n        normalized = []\n        for rel in relationships:\n            predicate = rel.get('relationship', '')\n            if predicate in self.predicate_map:\n                rel['relationship'] = self.predicate_map[predicate]\n            normalized.append(rel)\n        return normalized",
        "new_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Normalize predicates with semantic validation.\"\"\"\n        normalized = []\n        \n        for rel in relationships:\n            predicate = rel.get('relationship', '').lower()\n            source = rel.get('source', '')\n            target = rel.get('target', '')\n            \n            # Detect entity types\n            source_type = self._detect_entity_type(source)\n            \n            # Check semantic compatibility\n            if source_type and source_type in self.entity_type_predicates:\n                rules = self.entity_type_predicates[source_type]\n                \n                # Check if predicate is forbidden for this entity type\n                if any(forbidden in predicate for forbidden in rules['forbidden']):\n                    # Try to find replacement\n                    for forbidden, replacement in rules['replacements'].items():\n                        if forbidden in predicate:\n                            rel['relationship'] = replacement\n                            rel['quality_flags'] = rel.get('quality_flags', []) + ['PREDICATE_SEMANTICALLY_CORRECTED']\n                            rel['original_relationship'] = predicate\n                            break\n            \n            # Apply standard normalization\n            if rel['relationship'] in self.predicate_map:\n                rel['relationship'] = self.predicate_map[rel['relationship']]\n            \n            normalized.append(rel)\n        return normalized\n    \n    def _detect_entity_type(self, entity: str) -> str:\n        \"\"\"Detect entity type from entity string.\"\"\"\n        entity_lower = entity.lower()\n        \n        # Book detection\n        if any(keyword in entity_lower for keyword in ['handbook', 'book', 'guide', 'manual']):\n            return 'Book'\n        \n        # Person detection (capitalized, contains name patterns)\n        if entity and entity[0].isupper() and ' ' in entity:\n            return 'Person'\n        \n        return None",
        "validation": "Test with V7 examples: (Soil Stewardship Handbook, helps heal, planet)"
      }
    },
    {
      "operation_id": "change_012",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/bibliographic_parser.py",
      "priority": "MEDIUM",
      "rationale": "Fixes 1 dedication misattribution (0.11%). Need to detect dedication statements and extract correctly.",
      "risk_level": "low",
      "affected_issue_category": "Dedication Misattributed as Authorship",
      "expected_improvement": "Fixes 1/1 dedication error (100% resolution)",
      "edit_details": {
        "target_function": "BibliographicCitationParser.__init__",
        "old_content": "    def __init__(self):\n        self.citation_patterns = [\n            r'^([A-Z][a-z]+,\\s+[A-Z][a-z]+)\\.',\n        ]",
        "new_content": "    def __init__(self):\n        self.citation_patterns = [\n            r'^([A-Z][a-z]+,\\s+[A-Z][a-z]+)\\.',\n        ]\n        \n        # Dedication patterns\n        self.dedication_patterns = [\n            r'(?:this book is )?dedicated to (.+)',\n            r'in memory of (.+)',\n            r'for my (.+)',\n            r'to my (.+)',\n        ]\n        \n        self.dedication_verbs = ['dedicated', 'authored', 'wrote', 'authorship']",
        "validation": "Test: 'This book is dedicated to my children' \u2192 (Author, dedicated, Book to children)"
      }
    },
    {
      "operation_id": "change_013",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/bibliographic_parser.py",
      "priority": "MEDIUM",
      "rationale": "Add dedication detection logic to correct misattributed authorship.",
      "risk_level": "low",
      "affected_issue_category": "Dedication Misattributed as Authorship",
      "expected_improvement": "Enables dedication statement detection",
      "edit_details": {
        "target_function": "BibliographicCitationParser.process_batch",
        "old_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Process bibliographic citations.\"\"\"\n        processed = []\n        for rel in relationships:\n            # Existing citation processing\n            processed.append(rel)\n        return processed",
        "new_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Process bibliographic citations and dedications.\"\"\"\n        processed = []\n        \n        for rel in relationships:\n            evidence = rel.get('evidence_text', '').lower()\n            relationship = rel.get('relationship', '').lower()\n            \n            # Check for dedication statements\n            for pattern in self.dedication_patterns:\n                match = re.search(pattern, evidence)\n                if match and any(verb in relationship for verb in self.dedication_verbs):\n                    # This is a dedication, not authorship\n                    recipients = match.group(1)\n                    \n                    rel['relationship'] = 'dedicated'\n                    # Append recipients to target if it's a book\n                    if 'handbook' in rel.get('target', '').lower() or 'book' in rel.get('target', '').lower():\n                        rel['target'] = f\"{rel['target']} to {recipients}\"\n                    \n                    rel['quality_flags'] = rel.get('quality_flags', []) + ['DEDICATION_CORRECTED']\n                    rel['original_relationship'] = relationship\n                    break\n            \n            processed.append(rel)\n        return processed",
        "validation": "Test with V7 dedication example"
      }
    },
    {
      "operation_id": "change_014",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/figurative_language_detector.py",
      "priority": "MEDIUM",
      "rationale": "Normalizes 3 metaphorical descriptions (0.32%). Current detector flags metaphors but doesn't normalize them to literal equivalents.",
      "risk_level": "low",
      "affected_issue_category": "Figurative Language Treated as Factual + Metaphorical Book Descriptions",
      "expected_improvement": "Fixes 3/3 metaphorical descriptions (100% resolution)",
      "edit_details": {
        "target_function": "FigurativeLanguageDetector.__init__",
        "old_content": "    def __init__(self):\n        self.metaphorical_terms = ['sacred', 'magic', 'spiritual', 'wedded']",
        "new_content": "    def __init__(self):\n        self.metaphorical_terms = ['sacred', 'magic', 'spiritual', 'wedded']\n        \n        # Metaphorical predicate mappings to literal equivalents\n        self.metaphor_normalizations = {\n            'is a road-map': 'provides guidance',\n            'is a compass': 'provides direction',\n            'is a guide': 'provides guidance',\n            'is wedded to': 'depends on',\n            'is tied to': 'depends on',\n            'is connected to': 'relates to',\n            'road-map of sorts': 'guide',\n            'compass for': 'guide for'\n        }",
        "validation": "Test: (Book, is a road-map, for soil stewardship) \u2192 (Book, provides guidance, for soil stewardship)"
      }
    },
    {
      "operation_id": "change_015",
      "operation_type": "CODE_FIX",
      "file_path": "modules/pass2_5_postprocessing/figurative_language_detector.py",
      "priority": "MEDIUM",
      "rationale": "Add normalization logic to replace metaphorical predicates with literal equivalents.",
      "risk_level": "low",
      "affected_issue_category": "Figurative Language Treated as Factual",
      "expected_improvement": "Enables metaphor normalization",
      "edit_details": {
        "target_function": "FigurativeLanguageDetector.process_batch",
        "old_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Flag figurative language.\"\"\"\n        flagged = []\n        for rel in relationships:\n            relationship = rel.get('relationship', '')\n            if any(term in relationship.lower() for term in self.metaphorical_terms):\n                rel['quality_flags'] = rel.get('quality_flags', []) + ['FIGURATIVE_LANGUAGE']\n            flagged.append(rel)\n        return flagged",
        "new_content": "    def process_batch(self, relationships: List[Dict]) -> List[Dict]:\n        \"\"\"Detect and normalize figurative language.\"\"\"\n        processed = []\n        \n        for rel in relationships:\n            relationship = rel.get('relationship', '').lower()\n            target = rel.get('target', '').lower()\n            \n            # Check for metaphorical predicates and normalize\n            normalized = False\n            for metaphor, literal in self.metaphor_normalizations.items():\n                if metaphor in relationship:\n                    rel['relationship'] = literal\n                    rel['quality_flags'] = rel.get('quality_flags', []) + ['METAPHOR_NORMALIZED']\n                    rel['original_relationship'] = relationship\n                    normalized = True\n                    break\n                \n                # Also check target for metaphorical terms\n                if metaphor in target:\n                    rel['target'] = target.replace(metaphor, literal)\n                    rel['quality_flags'] = rel.get('quality_flags', []) + ['METAPHOR_NORMALIZED_TARGET']\n                    rel['original_target'] = target\n                    normalized = True\n                    break\n            \n            # Flag remaining figurative language\n            if not normalized and any(term in relationship for term in self.metaphorical_terms):\n                rel['quality_flags'] = rel.get('quality_flags', []) + ['FIGURATIVE_LANGUAGE']\n            \n            processed.append(rel)\n        return processed",
        "validation": "Test all 3 V7 metaphorical examples"
      }
    }
  ],
  "priorities": {
    "immediate": [
      "change_001: Create PraiseQuoteDetector module (CRITICAL) - Fixes 4 reversed authorship errors",
      "change_002-004: Enhance PronounResolver with possessive + coreference (CRITICAL) - Fixes 18 pronoun errors"
    ],
    "short_term": [
      "change_005-006: Enhance VagueEntityDetector with context replacement (HIGH) - Fixes 8 vague targets",
      "change_007: Add philosophical statement filter to Pass 2 prompt (HIGH) - Filters 6 abstract claims",
      "change_008-009: Enhance ListSplitter for 'and' conjunctions (HIGH) - Fixes 4 incomplete splits"
    ],
    "medium_term": [
      "change_010-011: Add semantic validation to PredicateNormalizer (MEDIUM) - Fixes 2 wrong predicates",
      "change_012-013: Add dedication detection to BibliographicParser (MEDIUM) - Fixes 1 dedication error",
      "change_014-015: Add metaphor normalization to FigurativeLanguageDetector (MEDIUM) - Normalizes 3 metaphors"
    ]
  },
  "testing_strategy": {
    "unit_tests": [
      "Test PraiseQuoteDetector with all 4 V7 reversed authorship examples",
      "Test PronounResolver with all 18 V7 pronoun examples (8 unresolved + 10 possessive)",
      "Test VagueEntityDetector with all 8 V7 vague target examples",
      "Test ListSplitter with 'communities and planet' pattern",
      "Test PredicateNormalizer with 'Book helps heal planet' example",
      "Test BibliographicParser with dedication statement",
      "Test FigurativeLanguageDetector with 'road-map' metaphor"
    ],
    "integration_tests": [
      "Run full V8 extraction on Soil Handbook pages 1-15 (front matter)",
      "Compare V8 vs V7 on same 924 relationships",
      "Verify all Pass 2.5 modules run in correct order (PraiseQuoteDetector FIRST)"
    ],
    "regression_tests": [
      "Ensure V8 doesn't introduce new errors in previously correct relationships",
      "Verify V8 maintains or improves V7 quality on non-issue relationships"
    ],
    "success_criteria": [
      "Critical issues: 4 \u2192 0 (100% reduction)",
      "High priority issues: 12 \u2192 2 (83% reduction)",
      "Total issue rate: 6.71% \u2192 <3% (55% reduction)",
      "Meets production threshold: <5% issue rate \u2713"
    ]
  },
  "rollback_plan": {
    "backup_location": "kg_extraction_playbook_backups/v7_meta_ace/",
    "backup_command": "python scripts/backup_version.py --version v7_meta_ace",
    "rollback_command": "python scripts/rollback_version.py --to v7_meta_ace",
    "rollback_conditions": [
      "If V8 total issue rate > V7 (6.71%)",
      "If V8 introduces >10 new critical errors",
      "If V8 extraction crashes or times out",
      "If any unit test fails"
    ],
    "rollback_validation": [
      "Run V7 extraction on test sample",
      "Verify V7 issue rate matches baseline (6.71%)",
      "Confirm all V7 modules functional"
    ]
  },
  "estimated_impact_summary": {
    "before_v8": {
      "critical_issues": 4,
      "high_priority_issues": 12,
      "medium_priority_issues": 28,
      "mild_issues": 18,
      "total_issues": 62,
      "issue_rate": "6.71%",
      "grade": "B+"
    },
    "after_v8": {
      "critical_issues": 0,
      "high_priority_issues": 2,
      "medium_priority_issues": 8,
      "mild_issues": 15,
      "total_issues": 25,
      "issue_rate": "~2.7%",
      "grade": "A-"
    },
    "improvements": {
      "critical_reduction": "100% (4 \u2192 0)",
      "high_priority_reduction": "83% (12 \u2192 2)",
      "total_issue_reduction": "60% (62 \u2192 25)",
      "issue_rate_reduction": "60% (6.71% \u2192 2.7%)",
      "production_ready": "YES - Well below 5% threshold"
    }
  },
  "risk_assessment": {
    "low_risk_changes": [
      "change_001: New module, no existing code modified",
      "change_005-006: Enhances existing detector, backward compatible",
      "change_007: Prompt enhancement, easily reversible",
      "change_008-009: Expands pattern matching, backward compatible",
      "change_010-011: Adds validation layer, doesn't break existing",
      "change_012-013: Adds detection, doesn't modify existing logic",
      "change_014-015: Adds normalization, backward compatible"
    ],
    "medium_risk_changes": [
      "change_002-004: Significant pronoun resolver rewrite - needs thorough testing"
    ],
    "high_risk_changes": [],
    "mitigation_strategies": {
      "change_002-004": "Extensive unit tests with all 18 V7 examples, fallback to generic resolution if coreference fails, gradual rollout"
    }
  },
  "metadata": {
    "curation_date": "2025-10-12T23:15:57.475998",
    "source_version": 7,
    "target_version": 8,
    "reflector_analysis_id": null,
    "curator_version": "1.0_claude",
    "model_used": "claude-sonnet-4-5-20250929"
  }
}